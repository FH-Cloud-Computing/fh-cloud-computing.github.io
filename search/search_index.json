{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the Cloud Computing course of September 2020! On this page you will find all learning materials you need to learn in order to pass the course. About the Course # Cloud Computing Learning approach: Remote learning Educational materials in writing. Videos and slide decks are available for the lecture part Videos of all demos are available. Source code is available on GitHub for all demos. Homework preparation tasks / learning diary, project work. Online consultation for participants once a week. 4 ECTS, roughly 112 hours of study (5-7 hours of study per week recommended) Lectures are on the lectures page . Grading is described on the grading page . Your homework assignment is described on the homework page Deadlines are described on the deadlines page . Testing is described on the testing page . Find help on the getting help page . About us # Peter Wenzl # E-mail: peter.wenzl@edu.fh-campuswien.ac.at Computer Science Master (Dipl. Ing.), TU Wien, 2000 Telecoms Focused Career Ericsson Austria mobilkom Austria Oracle Austria GmBH (CGBU) Frequentis AG Janos Pasztor # E-mail: janos.pasztor@edu.fh-campuswien.ac.at Linkedin: www.linkedin.com/in/janoszen/ Website: pasztor.at Software developer and DevOps engineer background (10+ years experience) Web Focused Career Currently works as a Developer Advocate at A1 Telekom / A1 Digital / Exoscale","title":"Overview"},{"location":"#about_the_course","text":"Cloud Computing Learning approach: Remote learning Educational materials in writing. Videos and slide decks are available for the lecture part Videos of all demos are available. Source code is available on GitHub for all demos. Homework preparation tasks / learning diary, project work. Online consultation for participants once a week. 4 ECTS, roughly 112 hours of study (5-7 hours of study per week recommended) Lectures are on the lectures page . Grading is described on the grading page . Your homework assignment is described on the homework page Deadlines are described on the deadlines page . Testing is described on the testing page . Find help on the getting help page .","title":"About the Course"},{"location":"#about_us","text":"","title":"About us"},{"location":"#peter_wenzl","text":"E-mail: peter.wenzl@edu.fh-campuswien.ac.at Computer Science Master (Dipl. Ing.), TU Wien, 2000 Telecoms Focused Career Ericsson Austria mobilkom Austria Oracle Austria GmBH (CGBU) Frequentis AG","title":"Peter Wenzl"},{"location":"#janos_pasztor","text":"E-mail: janos.pasztor@edu.fh-campuswien.ac.at Linkedin: www.linkedin.com/in/janoszen/ Website: pasztor.at Software developer and DevOps engineer background (10+ years experience) Web Focused Career Currently works as a Developer Advocate at A1 Telekom / A1 Digital / Exoscale","title":"Janos Pasztor"},{"location":"deadlines/","text":"Sprint 1: Instance Pools # Deadline: 1 st of October 2020 In this sprint you must demonstrate your ability to set up an instance pool and a network load balancer. Pass criteria: your webservice must answer on an IP address and balance trafic across all instances running in an instance pool. The number of instances will be changed in the demonstration and your web service must adapt accordingly. Sprint 2: Monitoring # Deadline: 1 st of November 2020 In this sprint you must demonstrate your ability to monitor a varying number of instances set up on an instance pool in the previous sprint. Pass criteria: Your monitoring instance must be set up with Prometheus and Grafana running. Prometheus must track the instances in the instance pool using custom service discovery and collect their CPU usage in a graph in Grafana. Sprint 3: Autoscaling # Deadline: 1 st of December 2020 In this sprint you must demonstrate your ability to receive a webhook from Grafana and adjust the number of instances in the instance pool from the previous sprint under load. Pass criteria: Your service will be hit with a large number of requests and it must scale up as outlined in the project work document .","title":"Deadlines"},{"location":"deadlines/#sprint_1_instance_pools","text":"Deadline: 1 st of October 2020 In this sprint you must demonstrate your ability to set up an instance pool and a network load balancer. Pass criteria: your webservice must answer on an IP address and balance trafic across all instances running in an instance pool. The number of instances will be changed in the demonstration and your web service must adapt accordingly.","title":"Sprint 1: Instance Pools"},{"location":"deadlines/#sprint_2_monitoring","text":"Deadline: 1 st of November 2020 In this sprint you must demonstrate your ability to monitor a varying number of instances set up on an instance pool in the previous sprint. Pass criteria: Your monitoring instance must be set up with Prometheus and Grafana running. Prometheus must track the instances in the instance pool using custom service discovery and collect their CPU usage in a graph in Grafana.","title":"Sprint 2: Monitoring"},{"location":"deadlines/#sprint_3_autoscaling","text":"Deadline: 1 st of December 2020 In this sprint you must demonstrate your ability to receive a webhook from Grafana and adjust the number of instances in the instance pool from the previous sprint under load. Pass criteria: Your service will be hit with a large number of requests and it must scale up as outlined in the project work document .","title":"Sprint 3: Autoscaling"},{"location":"grading/","text":"Grade construction # 55% written examination (individual) 45% project work (15% per exercise) Project work grading # 5% in each exercise for implementing it using an automation framework such as Terraform or Ansible. It must have the ability to install the exercise in an empty Exoscale account without human interaction. 5% in each exercise for demonstrating a working functionality 5% in each exercise for uploading the code to GitHub in a close to working state Marks # Positive grade: Minimum 60% score in written exam plus 60% of overall score required 1 2 3 4 5 90% \u2014 100% 80% \u2014 89% 70% \u2014 79% 60% \u2014 69% <60%","title":"Grading"},{"location":"grading/#grade_construction","text":"55% written examination (individual) 45% project work (15% per exercise)","title":"Grade construction"},{"location":"grading/#project_work_grading","text":"5% in each exercise for implementing it using an automation framework such as Terraform or Ansible. It must have the ability to install the exercise in an empty Exoscale account without human interaction. 5% in each exercise for demonstrating a working functionality 5% in each exercise for uploading the code to GitHub in a close to working state","title":"Project work grading"},{"location":"grading/#marks","text":"Positive grade: Minimum 60% score in written exam plus 60% of overall score required 1 2 3 4 5 90% \u2014 100% 80% \u2014 89% 70% \u2014 79% 60% \u2014 69% <60%","title":"Marks"},{"location":"help/","text":"Everybody needs help, and since this is a new situation we have prepared a few channels where you can get help. Before you ask for help # Make sure you strip the code you have a problem with of all unnecessary code, comments, etc. Make sure you upload your code to GitHub so others can take a look at it. Make sure you think through and describe your problem in more detail as you would in a conversation, as digitally it may be harder to follow. Where to ask for help # The primary avenue of getting help is on the Slack channel for this course . Join the weekly online consultation sessions. If you need to send us something, please do so on the email addresses on the introduction page .","title":"Getting help"},{"location":"help/#before_you_ask_for_help","text":"Make sure you strip the code you have a problem with of all unnecessary code, comments, etc. Make sure you upload your code to GitHub so others can take a look at it. Make sure you think through and describe your problem in more detail as you would in a conversation, as digitally it may be harder to follow.","title":"Before you ask for help"},{"location":"help/#where_to_ask_for_help","text":"The primary avenue of getting help is on the Slack channel for this course . Join the weekly online consultation sessions. If you need to send us something, please do so on the email addresses on the introduction page .","title":"Where to ask for help"},{"location":"lectures/","text":"Lecture 1: Introduction # NIST Definition of Cloud IaaS, PaaS, SaaS, FaaS Public vs. Private Cloud Basic \u201chosting\u201d service vs. managed service Benefits/Risks/Regulations: Scalability, Privacy, GDPR, Safe Harbor/Privacy Shield Business Models: Overbooking, Pay-per-Use, Standardization & Automation Go to lecture \u00bb Lecture 2: Cloud capabilities # Cloud roles: Platform/Service provider vs. customers (developers, enterprises) Cloud architectures & definitions Operational requiremens Cloud performance Cloud service provisioning Extra Lectures: Various cloud stacks, Cloud networking, Security concepts Go to lecture \u00bb Lecture 3: IaaS introduction # Intro to Cloud Platforms (Exoscale, Amazon AWS/EC2 and Google Cloud Platform) Virtual Server+Storage+Networking capabilities Automation via Terraform Hands-on demos Go to lecture \u00bb Lecture 4: Beyond IaaS # Container Services (Docker & Kubernetes) Differences Container vs. classical server virtualization PaaS, SaaS, FaaS (Concepts, Examples) Hands-on demos Go to lecture \u00bb Lecture 5: Cloud-native software development # Cloud-native software basics & definitions Microservices 12-factor Apps Frameworks and tools Hands-on demos Go to lecture \u00bb","title":"Overview"},{"location":"lectures/#lecture_1_introduction","text":"NIST Definition of Cloud IaaS, PaaS, SaaS, FaaS Public vs. Private Cloud Basic \u201chosting\u201d service vs. managed service Benefits/Risks/Regulations: Scalability, Privacy, GDPR, Safe Harbor/Privacy Shield Business Models: Overbooking, Pay-per-Use, Standardization & Automation Go to lecture \u00bb","title":"Lecture 1: Introduction"},{"location":"lectures/#lecture_2_cloud_capabilities","text":"Cloud roles: Platform/Service provider vs. customers (developers, enterprises) Cloud architectures & definitions Operational requiremens Cloud performance Cloud service provisioning Extra Lectures: Various cloud stacks, Cloud networking, Security concepts Go to lecture \u00bb","title":"Lecture 2: Cloud capabilities"},{"location":"lectures/#lecture_3_iaas_introduction","text":"Intro to Cloud Platforms (Exoscale, Amazon AWS/EC2 and Google Cloud Platform) Virtual Server+Storage+Networking capabilities Automation via Terraform Hands-on demos Go to lecture \u00bb","title":"Lecture 3: IaaS introduction"},{"location":"lectures/#lecture_4_beyond_iaas","text":"Container Services (Docker & Kubernetes) Differences Container vs. classical server virtualization PaaS, SaaS, FaaS (Concepts, Examples) Hands-on demos Go to lecture \u00bb","title":"Lecture 4: Beyond IaaS"},{"location":"lectures/#lecture_5_cloud-native_software_development","text":"Cloud-native software basics & definitions Microservices 12-factor Apps Frameworks and tools Hands-on demos Go to lecture \u00bb","title":"Lecture 5: Cloud-native software development"},{"location":"lectures/1-cloud-intro/","text":"Introduction to the cloud # As the popular saying goes: The cloud is just somebody else's computer. There is no magic, just using the cloud does not magically solve problems we are having with a traditional infrastructure. This section will teach you how a cloud is built and what the typical services are that they offer as well as the pitfalls which may come with such setups. What is a Server? # In a hurry? Servers: Redundant, hot-swap hardware (power supply, fans, etc) Flat build profile for rack mounts Out-Of-Bounds management interface for monitoring and remote management In older times, servers were completely different from the machines we used for regular work. Not just in weight and form factor, but in architecture. The landscape would stretch from SPARC and Power architectures to the x86 architecture we use in our PCs. Over time, however, the x86 architecture took over to the point where a server today, from an architectural standpoint, is exactly the same as the machine you are using right now. This means that you can copy the machine you are using onto a server and chances are it will run without any modification. The only notable exception is the rise of the ARM architecture which is popular in phones and tables and is known for its low power consumption. In recent years there has been a small but noticeable trend to run ARM in a datacenter. At home it may not matter if your computer uses 200 or 300 watts of power. In a datacenter, at the scale of hundreds, thousands or tens of thousands of servers, saving even a few percent of power will translate to huge cost savings. The difference in build is, however, quite apparent. While some servers, mainly built for office use, have the standard \u201ctower\u201d build, most servers have a flat profile designed to be mounted in racks as displayed on the picture. Since most servers are not high enough to take full size expansion cards (graphics cards, network cards, etc), servers may contain a separate removable component for these usually called a riser. An HP Proliant G5 server pulled out of its rack. Source: Wikipedia Server racks are standardized closets that have mounting screws for rails that allow pulling servers out even mid operation and replace components while the server is running. Servers also come with a high level of redundancy. While you may have a single power supply in your home computer, servers typically have two that are able to take power from different power inputs. This makes sure that the server keeps running even if one of the two power supplies fail, or if one of the two power inputs goes down. Also in contrast to your home setup these servers contain an Out-Of-Bounds Management interface that allows remote management of servers even when they are turned off. The hardware components built into the server report their health status to this OOB management interface which allows the simultaneous monitoring of thousands of machines. Note This is a fairly generic description of servers. Different vendors may chose to leave out certain features of their more \u201cbudget\u201d line of servers, or call certain components differently. HP, for example, calls their OOBM \u201cIntegrated Lights Out\u201d, Dell \u201cDRAC - Dell Remote Access Control\u201d, etc. The Anatomy of a Datacenter # In a hurry? Datacenter components: Racks to house servers Larger customers have cages for their racks Cabling under the floor Redundant cooling, fire suppression systems and power supply Eco friendliness is becoming a factor Some datacenters provide internet connectivity Since the cloud is just somebody else's computer, that computer needs to be hosted somewhere. Servers are almost exclusively hosted in datacenters. Let's take a look at what is involved in running a datacenter. First of all, as mentioned above, most servers are going to be rack-mounted so you need a bunch of racks. These racks are installed in rows, often with a fake floor to allow for cabling to go under the floor. A datacenter with racks. Source: Wikipedia Since servers produce a lot of heat, a datacenter also requires cooling. There are a variety of ways to solve cooling, some are more \u201cgreen\u201d than others. Some datacenters, for example, opt to install a \u201ccold aisles\u201d where the cold air is pumped between two rack rows and is pushed through the racks to cool the servers. Apart from cooling, datacenters also require automated fire suppression systems simply because of the amount of electricity going through. Datacenters usually go with a non-destructive fire suppression system such as lowering the oxygen content of the air enough to stop the fire. All critical systems in a datacenter (power, cooling, fire suppression systems) are usually built in a redundant fashion because the loss of either of those systems will potentially mean a complete shutdown for the datacenter. Datacenter operators usually have further contingency plans in place, too, such as a UPS (battery) system, diesel generator, fuel truck on standby, hotline to the fire department, etc. to make sure the datacenter can keep its required uptime. On the networking side of things, matters get slightly more complicated. Some datacenter providers also offer you the ability to use their network uplink (also redundant), but larger customers will prefer to host their own networking equipment and negotiate their own internet uplink contracts. Since there is no generic rule for how datacenters handle this, we will dispense with a description. It is also worth noting that larger customers (banks, cloud providers, etc) usually prefer to have their own racks in a separated gated area called a \u201ccage\u201d to which they control access. The Anatomy of the Internet # In a hurry? Internet: IP ranges are advertised using BGP Providers connect direcly or using internet exchanges 16 global providers form the backbone of the internet (tier 1) Once the physical infrastructure is set up there is also the question of how to connect to the Internet. As mentioned before, networks can be very complicated and there is no one size fits all solution. Smaller customers will typically use the network infrastructure provided by the datacenter while larger customers will host their own network equipment. Again, generally speaking racks will be equipped with a Top-of-Rack switch to provide layer 2 (Ethernet) connectivity between servers. Several ToR may have interconnects between each other and are usually connected to one or more routers. Routers provide layer 3 (IP) routing to other customers in the same datacenter, internet exchange , or may be connected via dedicated fiber to another provider. Note If you are not familiar with computer networks we recommend giving the Geek University CCNA course a quick read . While you will not need everything, you will have to understand how IP addresses, netmasks, etc work in order to pass this course. Providers on the internet exchange data about which network they are hosting using the Border Gateway Protocol . Each provider's router announces the IP address ranges they are hosting to their peer providers, who in turn forward these announcements in an aggregated form to other providers. Providers have agreements with each other, or with an Internet Exchange, about exchanging a certain amount of traffic. These agreements may be paid if the traffic is very asymmetric or one provider is larger than the other. Alternatively providers can come to an arrangement to exchange traffic for free. Internet exchanges facilitate the exchange between many providers for a modest fee allowing cost-effective exchange of data. Depending on the exchange the rules are different. Local exchanges, for example, may only allow advertising local (in-country) addresses, while others are built for a specific purpose. Generally speaking providers can be classified into 3 categories. Tier 1 providers are the global players that are present on every continent. They form the backbone of the Internet. At the time of writing there are 16 such networks . Tier 2 are the providers who are directly connected to the tier 1 providers, while tier 3 is everyone else. Software stack # In a hurry? Software stack: Virtualization Operating system Application runtime Application The purpose of all this is, of course, to run an application. Each server hosts an operating system which is responsible for managing the hardware. Operating systems provide a simplified API for applications to do hardware-related operations such as dealing with files or talking to the network. This part of the operating system is called the kernel. Other parts form the userland. The userland includes user applications such as a logging software. Specifically on Linux and Unix systems the userland also contains a package manager used to install other software. Modern x86 server CPUs (and some desktop CPUs) also have a number of features that help with virtualization. Virtualization lets the server administrator run multiple guest operating systems efficiently and share the server resources between them. Did you know? You can find out if an Intel CPU supports hardware virtualization by looking for the VT-x feature on the Intel ARK . Unfortunately AMD does not have an easy to use list but you can look for the AMD-V feature on AMD CPUs. Note Virtualization is different from containerization (which we will talk about later) in that with virtualization each guest operating system has its own kernel whereas containers share a kernel between them. There is one more important aspect of finally getting an application to run: the runtime environment. Except for a few rare occasions applications need a runtime environment. If the application is compiled to machine code they still need so-called shared libraries. Shared libraries are common across multiple applications and can be installed and updated independently from the application itself. This makes for a more efficient update process, but also means that the right set of libraries need to be installed for applications. If the applications are written higher level languages like Java, Javascript, PHP, etc. they need the appropriate runtime environment for that language. One notable exception to the runtime environment requirement is the programming language Go . Go compiles everything normally located in libraries into a single binary along with the application. This makes it exceptionally simple to deploy Go applications into containers. The Cloud # In a hurry? Typical cloud features: API Dynamic scaling Can be classified into IaaS, PaaS and SaaS All of the previously discussed things were available before the \u201ccloud\u201d. You could pay a provider to give you access to a virtual machine where you could run your applications. What changed with the cloud, however, is the fact that you no longer had to write a support ticket for changed and everything became self service. The cloud age started with an infamous e-mail from Jeff Bezos to his engineers in 2002 forcing them to use APIs to exchange data between teams. The exact e-mail is no longer available but it went along these lines: 1) All teams will henceforth expose their data and functionality through service interfaces. 2) Teams must communicate with each other through these interfaces. 3) There will be no other form of interprocess communication allowed: no direct linking, no direct reads of another team\u2019s data store, no shared-memory model, no back-doors whatsoever. The only communication allowed is via service interface calls over the network. 4) It doesn\u2019t matter what technology is used. HTTP, Corba, Pubsub, custom protocols \u2014 doesn\u2019t matter. 5) All service interfaces, without exception, must be designed from the ground up to be externalizable. That is to say, the team must plan and design to be able to expose the interface to developers in the outside world. No exceptions. 6) Anyone who doesn\u2019t do this will be fired. This marked the beginning of Amazon Web Services the first and also the most successful public cloud offering. The first public release of AWS was in 2004 with SQS their message queue service, and got completely overhauled in 2006 where the Elastic Compute (EC2) and the Simple Storage Service (S3) service made its first public appearance. The APIs provided by cloud providers allow for a large amount of flexibility. If new servers are needed they can be launched within a few minutes. If there are too many servers they can be deleted. The same goes for other services: with the API (and the appropriate billing model) comes flexibility to adapt to change. The other factor that makes it easy to adapt to change is of course the fact that these services are managed. The cloud customer doesn't need to hire a team of engineers to build a database service, for example, it can be consumed without knowing how exactly the database is set up. Generally speaking, cloud services can be classified into three categories: Infrastructure as a Service (IaaS) providing virtual machines and network infrastructure, Platform as a Service (PaaS) offering services for developers to use, and Software as a Service (SaaS) offering end-user services. Business Models # Private vs. Public cloud # In a hurry? Private cloud: Hosted on-premises or in the public cloud using only private connections Large cloud providers offer their services \u201cin a box\u201d to host yourself Managed Services # In a hurry? Managed services: Low entry cost Little in-house know-how required Vendor lock-in If problems arise they are hard to debug Benefits # Drawbacks # Regulations #","title":"1. Introduction to the Cloud"},{"location":"lectures/1-cloud-intro/#introduction_to_the_cloud","text":"As the popular saying goes: The cloud is just somebody else's computer. There is no magic, just using the cloud does not magically solve problems we are having with a traditional infrastructure. This section will teach you how a cloud is built and what the typical services are that they offer as well as the pitfalls which may come with such setups.","title":"Introduction to the cloud"},{"location":"lectures/1-cloud-intro/#what_is_a_server","text":"In a hurry? Servers: Redundant, hot-swap hardware (power supply, fans, etc) Flat build profile for rack mounts Out-Of-Bounds management interface for monitoring and remote management In older times, servers were completely different from the machines we used for regular work. Not just in weight and form factor, but in architecture. The landscape would stretch from SPARC and Power architectures to the x86 architecture we use in our PCs. Over time, however, the x86 architecture took over to the point where a server today, from an architectural standpoint, is exactly the same as the machine you are using right now. This means that you can copy the machine you are using onto a server and chances are it will run without any modification. The only notable exception is the rise of the ARM architecture which is popular in phones and tables and is known for its low power consumption. In recent years there has been a small but noticeable trend to run ARM in a datacenter. At home it may not matter if your computer uses 200 or 300 watts of power. In a datacenter, at the scale of hundreds, thousands or tens of thousands of servers, saving even a few percent of power will translate to huge cost savings. The difference in build is, however, quite apparent. While some servers, mainly built for office use, have the standard \u201ctower\u201d build, most servers have a flat profile designed to be mounted in racks as displayed on the picture. Since most servers are not high enough to take full size expansion cards (graphics cards, network cards, etc), servers may contain a separate removable component for these usually called a riser. An HP Proliant G5 server pulled out of its rack. Source: Wikipedia Server racks are standardized closets that have mounting screws for rails that allow pulling servers out even mid operation and replace components while the server is running. Servers also come with a high level of redundancy. While you may have a single power supply in your home computer, servers typically have two that are able to take power from different power inputs. This makes sure that the server keeps running even if one of the two power supplies fail, or if one of the two power inputs goes down. Also in contrast to your home setup these servers contain an Out-Of-Bounds Management interface that allows remote management of servers even when they are turned off. The hardware components built into the server report their health status to this OOB management interface which allows the simultaneous monitoring of thousands of machines. Note This is a fairly generic description of servers. Different vendors may chose to leave out certain features of their more \u201cbudget\u201d line of servers, or call certain components differently. HP, for example, calls their OOBM \u201cIntegrated Lights Out\u201d, Dell \u201cDRAC - Dell Remote Access Control\u201d, etc.","title":"What is a Server?"},{"location":"lectures/1-cloud-intro/#the_anatomy_of_a_datacenter","text":"In a hurry? Datacenter components: Racks to house servers Larger customers have cages for their racks Cabling under the floor Redundant cooling, fire suppression systems and power supply Eco friendliness is becoming a factor Some datacenters provide internet connectivity Since the cloud is just somebody else's computer, that computer needs to be hosted somewhere. Servers are almost exclusively hosted in datacenters. Let's take a look at what is involved in running a datacenter. First of all, as mentioned above, most servers are going to be rack-mounted so you need a bunch of racks. These racks are installed in rows, often with a fake floor to allow for cabling to go under the floor. A datacenter with racks. Source: Wikipedia Since servers produce a lot of heat, a datacenter also requires cooling. There are a variety of ways to solve cooling, some are more \u201cgreen\u201d than others. Some datacenters, for example, opt to install a \u201ccold aisles\u201d where the cold air is pumped between two rack rows and is pushed through the racks to cool the servers. Apart from cooling, datacenters also require automated fire suppression systems simply because of the amount of electricity going through. Datacenters usually go with a non-destructive fire suppression system such as lowering the oxygen content of the air enough to stop the fire. All critical systems in a datacenter (power, cooling, fire suppression systems) are usually built in a redundant fashion because the loss of either of those systems will potentially mean a complete shutdown for the datacenter. Datacenter operators usually have further contingency plans in place, too, such as a UPS (battery) system, diesel generator, fuel truck on standby, hotline to the fire department, etc. to make sure the datacenter can keep its required uptime. On the networking side of things, matters get slightly more complicated. Some datacenter providers also offer you the ability to use their network uplink (also redundant), but larger customers will prefer to host their own networking equipment and negotiate their own internet uplink contracts. Since there is no generic rule for how datacenters handle this, we will dispense with a description. It is also worth noting that larger customers (banks, cloud providers, etc) usually prefer to have their own racks in a separated gated area called a \u201ccage\u201d to which they control access.","title":"The Anatomy of a Datacenter"},{"location":"lectures/1-cloud-intro/#the_anatomy_of_the_internet","text":"In a hurry? Internet: IP ranges are advertised using BGP Providers connect direcly or using internet exchanges 16 global providers form the backbone of the internet (tier 1) Once the physical infrastructure is set up there is also the question of how to connect to the Internet. As mentioned before, networks can be very complicated and there is no one size fits all solution. Smaller customers will typically use the network infrastructure provided by the datacenter while larger customers will host their own network equipment. Again, generally speaking racks will be equipped with a Top-of-Rack switch to provide layer 2 (Ethernet) connectivity between servers. Several ToR may have interconnects between each other and are usually connected to one or more routers. Routers provide layer 3 (IP) routing to other customers in the same datacenter, internet exchange , or may be connected via dedicated fiber to another provider. Note If you are not familiar with computer networks we recommend giving the Geek University CCNA course a quick read . While you will not need everything, you will have to understand how IP addresses, netmasks, etc work in order to pass this course. Providers on the internet exchange data about which network they are hosting using the Border Gateway Protocol . Each provider's router announces the IP address ranges they are hosting to their peer providers, who in turn forward these announcements in an aggregated form to other providers. Providers have agreements with each other, or with an Internet Exchange, about exchanging a certain amount of traffic. These agreements may be paid if the traffic is very asymmetric or one provider is larger than the other. Alternatively providers can come to an arrangement to exchange traffic for free. Internet exchanges facilitate the exchange between many providers for a modest fee allowing cost-effective exchange of data. Depending on the exchange the rules are different. Local exchanges, for example, may only allow advertising local (in-country) addresses, while others are built for a specific purpose. Generally speaking providers can be classified into 3 categories. Tier 1 providers are the global players that are present on every continent. They form the backbone of the Internet. At the time of writing there are 16 such networks . Tier 2 are the providers who are directly connected to the tier 1 providers, while tier 3 is everyone else.","title":"The Anatomy of the Internet"},{"location":"lectures/1-cloud-intro/#software_stack","text":"In a hurry? Software stack: Virtualization Operating system Application runtime Application The purpose of all this is, of course, to run an application. Each server hosts an operating system which is responsible for managing the hardware. Operating systems provide a simplified API for applications to do hardware-related operations such as dealing with files or talking to the network. This part of the operating system is called the kernel. Other parts form the userland. The userland includes user applications such as a logging software. Specifically on Linux and Unix systems the userland also contains a package manager used to install other software. Modern x86 server CPUs (and some desktop CPUs) also have a number of features that help with virtualization. Virtualization lets the server administrator run multiple guest operating systems efficiently and share the server resources between them. Did you know? You can find out if an Intel CPU supports hardware virtualization by looking for the VT-x feature on the Intel ARK . Unfortunately AMD does not have an easy to use list but you can look for the AMD-V feature on AMD CPUs. Note Virtualization is different from containerization (which we will talk about later) in that with virtualization each guest operating system has its own kernel whereas containers share a kernel between them. There is one more important aspect of finally getting an application to run: the runtime environment. Except for a few rare occasions applications need a runtime environment. If the application is compiled to machine code they still need so-called shared libraries. Shared libraries are common across multiple applications and can be installed and updated independently from the application itself. This makes for a more efficient update process, but also means that the right set of libraries need to be installed for applications. If the applications are written higher level languages like Java, Javascript, PHP, etc. they need the appropriate runtime environment for that language. One notable exception to the runtime environment requirement is the programming language Go . Go compiles everything normally located in libraries into a single binary along with the application. This makes it exceptionally simple to deploy Go applications into containers.","title":"Software stack"},{"location":"lectures/1-cloud-intro/#the_cloud","text":"In a hurry? Typical cloud features: API Dynamic scaling Can be classified into IaaS, PaaS and SaaS All of the previously discussed things were available before the \u201ccloud\u201d. You could pay a provider to give you access to a virtual machine where you could run your applications. What changed with the cloud, however, is the fact that you no longer had to write a support ticket for changed and everything became self service. The cloud age started with an infamous e-mail from Jeff Bezos to his engineers in 2002 forcing them to use APIs to exchange data between teams. The exact e-mail is no longer available but it went along these lines: 1) All teams will henceforth expose their data and functionality through service interfaces. 2) Teams must communicate with each other through these interfaces. 3) There will be no other form of interprocess communication allowed: no direct linking, no direct reads of another team\u2019s data store, no shared-memory model, no back-doors whatsoever. The only communication allowed is via service interface calls over the network. 4) It doesn\u2019t matter what technology is used. HTTP, Corba, Pubsub, custom protocols \u2014 doesn\u2019t matter. 5) All service interfaces, without exception, must be designed from the ground up to be externalizable. That is to say, the team must plan and design to be able to expose the interface to developers in the outside world. No exceptions. 6) Anyone who doesn\u2019t do this will be fired. This marked the beginning of Amazon Web Services the first and also the most successful public cloud offering. The first public release of AWS was in 2004 with SQS their message queue service, and got completely overhauled in 2006 where the Elastic Compute (EC2) and the Simple Storage Service (S3) service made its first public appearance. The APIs provided by cloud providers allow for a large amount of flexibility. If new servers are needed they can be launched within a few minutes. If there are too many servers they can be deleted. The same goes for other services: with the API (and the appropriate billing model) comes flexibility to adapt to change. The other factor that makes it easy to adapt to change is of course the fact that these services are managed. The cloud customer doesn't need to hire a team of engineers to build a database service, for example, it can be consumed without knowing how exactly the database is set up. Generally speaking, cloud services can be classified into three categories: Infrastructure as a Service (IaaS) providing virtual machines and network infrastructure, Platform as a Service (PaaS) offering services for developers to use, and Software as a Service (SaaS) offering end-user services.","title":"The Cloud"},{"location":"lectures/1-cloud-intro/#business_models","text":"","title":"Business Models"},{"location":"lectures/1-cloud-intro/#private_vs_public_cloud","text":"In a hurry? Private cloud: Hosted on-premises or in the public cloud using only private connections Large cloud providers offer their services \u201cin a box\u201d to host yourself","title":"Private vs. Public cloud"},{"location":"lectures/1-cloud-intro/#managed_services","text":"In a hurry? Managed services: Low entry cost Little in-house know-how required Vendor lock-in If problems arise they are hard to debug","title":"Managed Services"},{"location":"lectures/1-cloud-intro/#benefits","text":"","title":"Benefits"},{"location":"lectures/1-cloud-intro/#drawbacks","text":"","title":"Drawbacks"},{"location":"lectures/1-cloud-intro/#regulations","text":"","title":"Regulations"},{"location":"lectures/2-capabilities/","text":"","title":"2. Cloud capabilities"},{"location":"lectures/3-iaas/","text":"","title":"3. Infrastructure as a Service"},{"location":"lectures/4-xaas/","text":"","title":"4. Beyond IaaS: PaaS, SaaS"},{"location":"lectures/5-cloud-native/","text":"","title":"5. Cloud-native software development"},{"location":"projectwork/","text":"You are the cloud architect for a small work-for-hire company. A client wants to hire you but they are sceptical about your abilities to build an autoscaling service. They propose a proof of concept: build a service that runs a web application that is deliberately slow and load test it. Your cloud management should automatically launch new cloud servers when the load is high and remove servers when demand is low. To accomplish this task the client provides you with a budget of 20 \u20ac for Exoscale which your project has to fit in. After taking a look at the capabilities of this cloud provider and discussing the constraints with your colleagues you decide that the following approach would be best: You are going to use Terraform to automate the setup and tear down of the cloud infrastructure. This is necessary because if you continuously use the cloud service you will not fit in the budget. You will use instance pools to manage the variable number of cloud servers and Network Load Balancers [TODO add link] to balance the traffic between them. You will set up a dedicated monitoring and management instance which will run Prometheus to automatically monitor a varying number of servers. You will write a custom service discovery agent that creates a file with the IP addresses of the machines in the instance pool for Prometheus to consume. On the instance pool you will deploy the Prometheus node exporter to monitor CPU usage. You will install Grafana to provide a monitoring dashboard and the ability to send webhooks. You will configure an alert webhook in Grafana that sends a webhook to an application written by you. If the average CPU usage is above 80%, or below 20% to scale up or down respectively a webhook is sent. You will write an application that receives this webhook and every 60 seconds scales the instance pool up or down if a webhook has been received. As you also have to demonstrate to the client that you can work in an agile methodology you agree in 4 week sprints with a demo at the end of each sprint as outlined in the deadlines document.","title":"Project work"},{"location":"testing/","text":"Testing is done using an interactive quiz: acadly.com Course \u201eCloud_2020\u201c, enrollment code NMWNZT (register with FH email address)","title":"Testing"}]}